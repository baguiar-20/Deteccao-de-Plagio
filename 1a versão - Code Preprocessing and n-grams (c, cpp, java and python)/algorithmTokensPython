import glob, os
from os.path import isfile
import errno
import re
from re import sub

def contARCHIVES(): #contador de arquivos
    cont = 0
    os.chdir(r"C:\Users\simon\algorithmPYTHON")
    for file in glob.glob("*.txt"):
#         print(file)
        cont += 1
    return cont

def removeEMPTYLINES(s): #remove linhas em  branco
    filtered = filter(lambda x: not re.match(r'^\s*$', x), s)
    frases = []
    for i in filtered:
        frases.append(i)
    return frases

def prePROCESSAM(texto): #remove comments and white spaces
    texto = texto.replace(" ", " AB ")
    texto = sub('".*?"', '" "',texto)
    texto = sub("'.*?'", "''",texto)
    texto = re.sub(r'(\"{2,3}[\s\n]*)(?:.*?[\s\n]*)*([\n\s]*\"{2,3})', r'\1\2', texto, flags=re.MULTILINE)
    texto = re.sub(r'#.*', '#',texto)  #comments in python  
    return texto

def functionTOKENS(text):
    tableTOKENSSIMBOLS = ['ab', 'aa', 'ad', 'ae', 'af', 'ag', 'ah', 'ai', 'aj', 'ak', 'al',
        'am', 'an', 'ao', 'ap', 'aq', 'ar', 'as', 'at', 'au', 'aw', 'az',
                         
        'ba', 'bb', 'bc', 'bd', 'be', 'bf', 'bg', 'bh','bi', 'bj', 'bk',
        'bl', 'bm', 'bn', 'bo', 'bp', 'bq', 'br', 'bs', 'bt',

        'bu', 'bv', 'bx', 'bw', 'bz', 'ca', 'cb', 'cc', 'cd', 'ce',
        'cf', 'cg', 'ch', 'ci', 'cj', 'ck', 'cl', 'cm', 'cn', 'co',

        'cp', 'cq', 'cr', 'cs', 'ct', 'cu', 'cv', 'cx', 'cw',
        'cz', 'da', 'db', 'dc', 'dd', 'de', 'df', 'dg', 'dh', 'di', 'dj',

        'dk', 'dl', 'dm', 'dn', 'do', 'dp', 'dq', 'dr', 'ds', 'dt', 'du', 'dv',
        'dx', 'dw', 'dz', 'ea', 'eb', 'ec', 'ed', 'ee',

        'ef', 'eg', 'eh', 'ei', 'ej', 'el', 'em', 'en', 'eo', 'ep',
        'eq', 'er', 'es', 'et', 'eu', 'ev', 'ex', 'ew', 'ez', 'fa',

        'fb', 'fc', 'fd', 'fe', 'ff', 'fg', 'fh', 'fi', 'fj', 'fl','ob','oc']
   
    #replace os símbolos pelos seus respectivos tokens
    text = text.replace("::", " ir ")
    text = text.replace("<<", " js ")
    text = text.replace("/*", " ir ")
    text = text.replace("*/", " is ")
    text = text.replace("//", " jt ")
    text = text.replace("++", " it ")
    text = text.replace("--", " iu ")
    text = text.replace("&&", " ob ")
    text = text.replace("||", " oc ")
    
    
    text = text.replace(":", " aa ")
    text = text.replace("(", " ad ")
    text = text.replace(")", " ae ")
    text = text.replace("[", " af ")
    text = text.replace("]", " ag ")
    text = text.replace('"', " ah ")
    text = text.replace("'", " ai ")
    text = text.replace("*", " aj ")
    text = text.replace("-", " ak ")
    text = text.replace("+", " al ")
    text = text.replace("%", " am ")
    text = text.replace("!", " an ")
    text = text.replace(".", " ao ")
    text = text.replace("/", " ap ")
    text = text.replace("#", " aq ")
    text = text.replace("=", " ar ")
    text = text.replace(">", " as ")
    text = text.replace("<", " at ")
    text = text.replace(",", " au ")
    text = text.replace("}", " aw ")
    text = text.replace("{", " az ")
   
    stringSPLIT = text.lower()#mantém os tokens minúsculos
    stringSPLIT = stringSPLIT.split()#divide o code em palavras em lista
   
    tableTOKENS = {#table com todos os tokens
        'and': 'ba', 'or':'bb', 'numpy':'bc', 'sys':'bd', 'os':'be', 'random':'bf',
        "math":'bg', 'False':'bh','None':'bi', 'True':'bj', 'as':'bk',
        'assert':'bl', 'break':'bm', 'class':'bn', 'continue':'bo', 'def':'bp',
        'bel':'bq', 'elif':'br', 'else':'bs', 'except':'bt',

        'finally': 'bu', 'for':'bv', 'from':'bx', 'global':'bw', 'if':'bz',
        'import':'ca', "in":'cb', 'is':'cc', 'lambda':'cd', 'nonlocal':'ce', 'not':'cf',
        'pass':'cg', 'raise':'ch', 'return':'ci', 'try':'cj',
        'while':'ck', 'with':'cl', 'yield':'cm', 'abs':'cn', 'all':'co',

        'any': 'cp', 'ascii':'cq', 'bin':'cr', 'bool':'cs', 'bytearray':'ct',
        'bytes':'cu', "callable":'cv', 'chr':'cx', 'classmethod':'cw',
        'compile':'cz', 'complex':'da', 'copyright':'db', 'credits':'dc',
        'delattr':'dd', 'dict':'de', 'dir':'df', 'divmod':'dg',
        'enumerate':'dh', 'eval':'di', 'exec':'dj',

        'exit': 'dk', 'filter':'dl', 'float':'dm', 'format':'dn', 'frozenset':'do',
        'getattr':'dp', "globals":'dq', 'hasattr':'dr', 'hash':'ds', 'help':'dt', 'hex':'du', 'id':'dv',
        'input':'dx','int':'dw', 'isinstance':'dz',
        'issubclass':'ea', 'iter':'eb', 'len':'ec', 'license':'ed', 'list':'ee',

        'locals': 'ef', 'map':'eg', 'max':'eh', 'memoryview':'ei', 'min':'ej',
        'next':'el', "object":'em', 'oct':'en', 'open':'eo', 'ord':'ep',
        'pow':'eq', 'print':'er', 'property':'es','quit':'et', 'range':'eu',
        'repr':'ev', 'reverse':'ex', 'round':'ew', 'set':'ez', 'setattr':'fa',

        'slice': 'fb', 'sorted':'fc', 'staticmethod':'fd', 'str':'fe', 'sum':'ff',
        'super':'fg', "tuple":'fh', 'type':'fi', 'vars':'fj',
        'zip':'fl',
    }

    for n, i in enumerate(stringSPLIT):#busca o token da palavra reservada
        for x, y in tableTOKENS.items():
            if i == x:
                stringSPLIT[n] = y
   
    print("teste: ", stringSPLIT)
    #remove itens q ñ possuem tokens(clean)
    for n, i in enumerate(stringSPLIT):
        if i not in tableTOKENSSIMBOLS:
#             print("Esse não está: ",n,"->", i)
            del stringSPLIT[n]
#                 stringSPLIT.pop(n)
#     print("teste")
#     print(stringSPLIT)
    return stringSPLIT

def calcNgram(listapalavras, n):
    ngrams = []
    for i in range(len(listapalavras)-(n-1)):
        ngrams.append(listapalavras[i:i+n])
    print(len(ngrams))
    return ngrams

# -------------MAIN---------------
arquivos = []
qtdeArqu = 0
qtdeARQUIVES = contARCHIVES()

for file in glob.glob("*.txt"):
    qtdeArqu += 1
    print("-----------CÓDIGO PYTHON", qtdeArqu, "--------")
    fp = open(file, "r", -1, 'utf-8')
    codeTEXT = fp.readlines()
    texto = removeEMPTYLINES(codeTEXT)
    print("----> PRE PROCESSING <----")
    stringTEXT = "".join(str(x) for x in texto)
    stringTEXT = re.sub('(?<=\/\*)[\s\S]*?(?=\*\/)', '', stringTEXT)
    stringTEXT = prePROCESSAM(stringTEXT)
    print(stringTEXT)
    print()
    print("----> TOKENIZE <----")
    stringTEXT = functionTOKENS(stringTEXT)
    print("Tokenização pronta: ", stringTEXT)
    print("Total tokens gerados: ", len(stringTEXT))
    print()
    print("----> N-GRAMS <----")
    stringTEXT = calcNgram(stringTEXT, 4)
    for n, i in enumerate(stringTEXT):
        print(n, "->", i)
    arquivos.append(stringTEXT)
    print()
